\subsection{Shannon's theorem}\cite{shannon1948mathematical}

So what is Shannon's objective? 
Through logarithmic entropy, Claude Shannon showed us that a certain amount of redundancy was necessary to be sure of getting the right message from the available list. However, thanks to data compression, we can greatly reduce redundancy without any loss of efficiency or accuracy.
But the aim behind all this is to maximize the variable C, which represents the maximum transmission capacity for a given time.

\subsection{Capacity}

The capacity C is defined in the Theorem 1 by $C = logW$, $W$ being the Determinant of the matrix of a communication system defined by:

Theorem 1: Let $b_{ij}^{(s)}$ be the duration of the $s^{th}$ symbol which is allowable in state i and leads to state j.
Then the channel capacity C is equal to $logW$ where $W$ is the largest real root of the determinant equation equation: $|\sum_s W{-b_{ij}^{(s)}} \delta{_{ij}}| = 0$

Where $\delta{_{ij}} = 1$ if $i = j$ 0 otherwise.